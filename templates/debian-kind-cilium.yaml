minimumLimaVersion: 1.1.0

base:
- template://_images/debian-custom
- template://_default/mounts

containerd:
  system: false
  user: false

provision:
- mode: system
  script: |
    #!/bin/bash
    set -eux -o pipefail
    command -v podman >/dev/null 2>&1 && test -e /etc/lima-podman && exit 0
    if [ ! -e /etc/systemd/system/podman.socket.d/override.conf ]; then
      mkdir -p /etc/systemd/system/podman.socket.d
      cat <<-EOF >/etc/systemd/system/podman.socket.d/override.conf
      [Socket]
      SocketUser={{.User}}
    EOF
    fi
    if [ ! -e /etc/tmpfiles.d/podman.conf ]; then
      mkdir -p /etc/tmpfiles.d
      echo "d /run/podman 0700 {{.User}} -" > /etc/tmpfiles.d/podman.conf
    fi
    apt install -y podman crun && touch /etc/lima-podman
- mode: system
  script: |
    #!/bin/bash
    set -eux -o pipefail
    systemctl --system enable --now podman.socket
- mode: user
  script: |
    #!/bin/bash
    set -euxo pipefail
    if command -v kind >/dev/null 2>&1 && sudo kind get clusters | grep -q "^multinode$"; then
      sudo podman start --all && sleep 60
    else
      [ "$(uname -m)" = aarch64 ] && curl -s -Lo ./kind https://kind.sigs.k8s.io/dl/v0.29.0/kind-linux-arm64
      chmod +x ./kind
      sudo mv ./kind /usr/local/bin/kind
      sudo kind create cluster --name multinode --config=/common/multinode.yaml
      mkdir -p ~/.kube
      sudo kind get kubeconfig --name multinode > ~/.kube/config
    fi
- mode: user
  script: |
    #!/bin/bash
    set -eux -o pipefail
    if ! command -v kubectl >/dev/null 2>&1; then
      sudo apt-get install apt-transport-https --yes
      curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.33/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
      sudo chmod 644 /etc/apt/keyrings/kubernetes-apt-keyring.gpg # allow unprivileged APT programs to read this keyring
      echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.33/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
      sudo chmod 644 /etc/apt/sources.list.d/kubernetes.list   # helps tools such as command-not-found to work correctly
      sudo apt-get update && sudo apt-get install -y kubectl
    else
      echo "kubectl is already installed"
    fi
- mode: user
  script: |
    #!/bin/bash
    set -eux -o pipefail
    if ! kubectl get daemonset -n kube-system cilium >/dev/null 2>&1; then
      sudo podman pull quay.io/cilium/cilium:v1.17.5
      sudo podman save quay.io/cilium/cilium:v1.17.5 -o cilium-v1.17.5.tar
      sudo kind load image-archive cilium-v1.17.5.tar --name multinode
      CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt)
      CLI_ARCH=amd64
      if [ "$(uname -m)" = "aarch64" ]; then CLI_ARCH=arm64; fi
      curl -L --fail --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}
      sha256sum --check cilium-linux-${CLI_ARCH}.tar.gz.sha256sum
      sudo tar xzvfC cilium-linux-${CLI_ARCH}.tar.gz /usr/local/bin
      rm cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}
      # Install Cilium using CLI
      cilium install --version 1.17.5 --set image.pullPolicy=IfNotPresent --set l2announcements.enabled=true --set l2announcements.interfaces[0]=eth0 --set externalIPs.enabled=true --set gatewayAPI.enabled=true
      # Wait for Cilium pods to be ready
      kubectl wait -n kube-system --selector=app.kubernetes.io/name=cilium-agent --for=condition=Ready pod --timeout=600s
      # Apply Cilium LB pool config
      kubectl apply -f /common/cilium_lb_pool.yaml
    else
      echo "Cilium is already installed. Skipping."
    fi
- mode: user
  script: |
    #!/bin/bash
    set -eux -o pipefail
    if ! kubectl get crds | grep gateway >/dev/null 2>&1; then
      kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/refs/heads/main/config/crd/standard/gateway.networking.k8s.io_gatewayclasses.yaml
      kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/refs/heads/main/config/crd/standard/gateway.networking.k8s.io_gateways.yaml
      kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/refs/heads/main/config/crd/standard/gateway.networking.k8s.io_grpcroutes.yaml
      kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/refs/heads/main/config/crd/standard/gateway.networking.k8s.io_httproutes.yaml
      kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/refs/heads/main/config/crd/standard/gateway.networking.k8s.io_referencegrants.yaml
      kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/refs/heads/main/config/crd/experimental/gateway.networking.k8s.io_tlsroutes.yaml
      kubectl wait -n kube-system --selector=app.kubernetes.io/name=cilium-agent --for=condition=Ready pod --timeout=600s
    fi

probes:
- script: |
    #!/bin/bash
    set -eux -o pipefail
    if ! timeout 30s bash -c "until command -v podman >/dev/null 2>&1; do sleep 3; done"; then
      echo >&2 "podman is not installed yet"
      exit 1
    fi
  hint: See "/var/log/cloud-init-output.log" in the guest

portForwards:
- guestSocket: "/run/podman/podman.sock"
  hostSocket: "{{.Dir}}/sock/podman.sock"

message: |
  ------
  Your VM is ready to use with kubectl and cilium installed with kube-proxy replacement.
  Happy LIMA!!!
  ------

mounts:
- location: "~"
- location: "/opt/lima/common"
  mountPoint: /common
  writable: false
- location: "/opt/lima/storage"
  mountPoint: /storage
  writable: true
- location: "{{.GlobalTempDir}}/lima"
  mountPoint: /tmp/lima
  writable: true

cpus: 5

memory: 8GiB

networks:
- lima: shared
  macAddress: "52:55:55:12:34:01"

arch: aarch64

disk: 100GiB

vmType: qemu
