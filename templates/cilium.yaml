minimumLimaVersion: 1.1.0

base:
- template://_images/fedora-custom
- template://_default/mounts

containerd:
  system: false
  user: false

provision:
- mode: system
  script: |
    #!/bin/bash
    set -eux -o pipefail
    command -v podman >/dev/null 2>&1 && test -e /etc/lima-podman && exit 0
    if [ ! -e /etc/systemd/system/podman.socket.d/override.conf ]; then
      mkdir -p /etc/systemd/system/podman.socket.d
      cat <<-EOF >/etc/systemd/system/podman.socket.d/override.conf
      [Socket]
      SocketUser={{.User}}
    EOF
    fi
    if [ ! -e /etc/tmpfiles.d/podman.conf ]; then
      mkdir -p /etc/tmpfiles.d
      echo "d /run/podman 0700 {{.User}} -" > /etc/tmpfiles.d/podman.conf
    fi
    dnf -y install --best podman && touch /etc/lima-podman
- mode: system
  script: |
    #!/bin/bash
    set -eux -o pipefail
    systemctl --system enable --now podman.socket
- mode: user
  script: |
    #!/bin/bash
    set -euxo pipefail
    if command -v kind >/dev/null 2>&1 && sudo kind get clusters | grep -q "^multinode$"; then
      sudo podman start --all && sleep 60
    else
      [ "$(uname -m)" = aarch64 ] && curl -s -Lo ./kind https://kind.sigs.k8s.io/dl/v0.29.0/kind-linux-arm64
      chmod +x ./kind
      sudo mv ./kind /usr/local/bin/kind
      sudo kind create cluster --name multinode --config /common/multinode.yaml
      mkdir -p ~/.kube
      sudo kind get kubeconfig --name multinode > ~/.kube/config
    fi
- mode: user
  script: |
    #!/bin/bash
    set -eux -o pipefail
    if ! command -v kubectl >/dev/null 2>&1; then
      cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
    [kubernetes]
    name=Kubernetes
    baseurl=https://pkgs.k8s.io/core:/stable:/v1.33/rpm/
    enabled=1
    gpgcheck=1
    gpgkey=https://pkgs.k8s.io/core:/stable:/v1.33/rpm/repodata/repomd.xml.key
    EOF
      sudo dnf install -y kubectl helm
    else
      echo "kubectl is already installed"
    fi
- mode: user
  script: |
    #!/bin/bash
    set -eux -o pipefail
    if ! helm status cilium -n kube-system >/dev/null 2>&1; then
      helm repo add cilium https://helm.cilium.io/
      sudo podman pull quay.io/cilium/cilium:v1.17.5
      sudo podman save quay.io/cilium/cilium:v1.17.5 -o cilium-v1.17.5.tar
      sudo kind load image-archive cilium-v1.17.5.tar --name multinode
      API_SERVER_IP=$(kubectl get pods -A -o wide | grep apiserver | awk '{print $7}')
      API_SERVER_PORT=6443
      helm install cilium cilium/cilium \
        --version 1.17.5 \
        --namespace kube-system \
        --set image.pullPolicy=IfNotPresent \
        --set ipam.mode=kubernetes \
        --set kubeProxyReplacement=true \
        --set k8sServiceHost=${API_SERVER_IP} \
        --set k8sServicePort=${API_SERVER_PORT} \
        --set l2announcements.enabled=true \
        --set l2announcements.interfaces[0]=eth0 \
        --set externalIPs.enabled=true
      kubectl wait -n kube-system --selector=app.kubernetes.io/name=cilium-agent --for=condition=Ready pod --timeout=600s && kubectl apply -f /common/cilium_lb_pool.yaml
    else
      echo "Cilium Helm release already installed in kube-system namespace. Skipping install."
    fi
- mode: user
  script: |
    #!/bin/bash
    set -eux -o pipefail
    if ! kubectl get crds | grep gateway >/dev/null 2>&1; then
      kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/refs/heads/main/config/crd/standard/gateway.networking.k8s.io_gatewayclasses.yaml
      kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/refs/heads/main/config/crd/standard/gateway.networking.k8s.io_gateways.yaml
      kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/refs/heads/main/config/crd/standard/gateway.networking.k8s.io_grpcroutes.yaml
      kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/refs/heads/main/config/crd/standard/gateway.networking.k8s.io_httproutes.yaml
      kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/refs/heads/main/config/crd/standard/gateway.networking.k8s.io_referencegrants.yaml
      kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/refs/heads/main/config/crd/experimental/gateway.networking.k8s.io_tlsroutes.yaml
      helm upgrade cilium cilium/cilium --version 1.17.5 \
        --namespace kube-system \
        --reuse-values \
        --set gatewayAPI.enabled=true
      kubectl rollout restart -n kube-system deploy/cilium-operator ds/cilium
      kubectl wait -n kube-system --selector=app.kubernetes.io/name=cilium-agent --for=condition=Ready pod --timeout=600s
    fi

probes:
- script: |
    #!/bin/bash
    set -eux -o pipefail
    if ! timeout 30s bash -c "until command -v podman >/dev/null 2>&1; do sleep 3; done"; then
      echo >&2 "podman is not installed yet"
      exit 1
    fi
  hint: See "/var/log/cloud-init-output.log" in the guest

portForwards:
- guestSocket: "/run/podman/podman.sock"
  hostSocket: "{{.Dir}}/sock/podman.sock"

message: |
  ------
  Your VM is ready to use with kubectl and cilium installed with kube-proxy replacement.
  Happy LIMA!!!
  ------

mounts:
- location: "~"
- location: "/opt/lima/common"
  mountPoint: /common
  writable: false
- location: "/opt/lima/storage"
  mountPoint: /storage
  writable: true
- location: "{{.GlobalTempDir}}/lima"
  mountPoint: /tmp/lima
  writable: true

cpus: 4

memory: 4GiB

networks:
- lima: shared
  macAddress: "52:55:55:12:34:07"

arch: aarch64

disk: 40GiB

vmType: qemu
